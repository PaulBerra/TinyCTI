#!/bin/bash

# TinyCTI Test Runner - Simplified and Organized
# Usage: ./scripts/test [options]

set -e

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
COVERAGE_MIN=80
PARALLEL_JOBS=auto

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# Logging functions
log() { echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"; }
success() { echo -e "${GREEN}✅ $1${NC}"; }
warning() { echo -e "${YELLOW}⚠️  $1${NC}"; }
error() { echo -e "${RED}❌ $1${NC}"; }

show_help() {
    cat << EOF
TinyCTI Test Runner

USAGE:
    ./scripts/test [OPTIONS]

OPTIONS:
    --unit           Run unit tests only
    --integration    Run integration tests only
    --coverage       Run with coverage report
    --quick          Skip slow tests
    --watch          Watch mode (auto-rerun on changes)
    --parallel       Run tests in parallel (default)
    --no-parallel    Disable parallel execution
    --verbose        Verbose output
    --quiet          Minimal output
    --help           Show this help

EXAMPLES:
    ./scripts/test                    # Run all tests
    ./scripts/test --unit --quick     # Quick unit tests
    ./scripts/test --coverage        # Tests with coverage
    ./scripts/test --integration     # Integration tests only
    ./scripts/test --watch            # Watch mode

ENVIRONMENT:
    COVERAGE_MIN     Minimum coverage percentage (default: 80)
    PARALLEL_JOBS    Number of parallel jobs (default: auto)

EOF
}

check_dependencies() {
    log "Checking dependencies..."
    
    if ! command -v python3 &> /dev/null; then
        error "Python 3 is required"
        exit 1
    fi
    
    if ! python3 -m pytest --version &> /dev/null; then
        error "pytest is not installed. Run: pip install pytest"
        exit 1
    fi
    
    success "Dependencies OK"
}

install_test_deps() {
    log "Installing test dependencies..."
    
    python3 -m pip install -q \
        pytest \
        pytest-cov \
        pytest-xdist \
        pytest-mock \
        requests-mock \
        coverage \
        || error "Failed to install test dependencies"
    
    success "Test dependencies installed"
}

run_unit_tests() {
    log "Running unit tests..."
    
    local args=("$PROJECT_ROOT/tests/unit/")
    
    # Add coverage if requested
    if [[ "$ENABLE_COVERAGE" == "true" ]]; then
        args+=(
            "--cov=$PROJECT_ROOT"
            "--cov-report=term-missing"
            "--cov-report=html:$PROJECT_ROOT/htmlcov"
            "--cov-report=xml:$PROJECT_ROOT/coverage.xml"
            "--cov-fail-under=$COVERAGE_MIN"
        )
    fi
    
    # Add parallel execution
    if [[ "$ENABLE_PARALLEL" == "true" ]]; then
        args+=("-n" "$PARALLEL_JOBS")
    fi
    
    # Add quick mode
    if [[ "$QUICK_MODE" == "true" ]]; then
        args+=("-m" "not slow")
    fi
    
    # Add verbosity
    if [[ "$VERBOSE" == "true" ]]; then
        args+=("-v")
    elif [[ "$QUIET" == "true" ]]; then
        args+=("-q")
    fi
    
    # Add output options
    args+=(
        "--tb=short"
        "--junitxml=$PROJECT_ROOT/test-results-unit.xml"
    )
    
    cd "$PROJECT_ROOT"
    if python3 -m pytest "${args[@]}"; then
        success "Unit tests passed"
        return 0
    else
        error "Unit tests failed"
        return 1
    fi
}

run_integration_tests() {
    log "Running integration tests..."
    
    local args=("$PROJECT_ROOT/tests/integration/")
    
    # Add parallel execution (fewer workers for integration)
    if [[ "$ENABLE_PARALLEL" == "true" ]]; then
        args+=("-n" "2")
    fi
    
    # Add quick mode
    if [[ "$QUICK_MODE" == "true" ]]; then
        args+=("-m" "not slow")
    fi
    
    # Add verbosity
    if [[ "$VERBOSE" == "true" ]]; then
        args+=("-v")
    elif [[ "$QUIET" == "true" ]]; then
        args+=("-q")
    fi
    
    # Add output options
    args+=(
        "--tb=short"
        "--junitxml=$PROJECT_ROOT/test-results-integration.xml"
    )
    
    cd "$PROJECT_ROOT"
    if python3 -m pytest "${args[@]}"; then
        success "Integration tests passed"
        return 0
    else
        error "Integration tests failed"
        return 1
    fi
}

watch_mode() {
    if ! command -v inotifywait &> /dev/null; then
        warning "inotifywait not found. Installing inotify-tools..."
        if command -v apt-get &> /dev/null; then
            sudo apt-get update -qq && sudo apt-get install -qq inotify-tools
        else
            error "Cannot install inotify-tools automatically. Please install manually."
            exit 1
        fi
    fi
    
    log "Starting watch mode..."
    log "Watching: $PROJECT_ROOT/{tinycti.py,tests/}"
    log "Press Ctrl+C to stop"
    
    # Run tests initially
    run_tests
    
    while true; do
        if inotifywait -r -e modify,create,delete \
            --include='\.py$' \
            "$PROJECT_ROOT/tinycti.py" \
            "$PROJECT_ROOT/tests/" \
            2>/dev/null; then
            
            echo ""
            log "Changes detected, re-running tests..."
            sleep 1
            run_tests
        fi
    done
}

run_tests() {
    local failed=false
    
    if [[ "$RUN_UNIT" == "true" ]]; then
        run_unit_tests || failed=true
    fi
    
    if [[ "$RUN_INTEGRATION" == "true" ]]; then
        run_integration_tests || failed=true
    fi
    
    if [[ "$failed" == "true" ]]; then
        return 1
    else
        return 0
    fi
}

generate_report() {
    log "Generating test report..."
    
    cat > "$PROJECT_ROOT/test-summary.txt" << EOF
TinyCTI Test Summary
===================
Date: $(date)
Configuration:
  - Coverage minimum: ${COVERAGE_MIN}%
  - Parallel execution: $ENABLE_PARALLEL
  - Quick mode: $QUICK_MODE
  - Unit tests: $RUN_UNIT
  - Integration tests: $RUN_INTEGRATION

Files generated:
EOF
    
    if [[ -f "$PROJECT_ROOT/htmlcov/index.html" ]]; then
        echo "  - Coverage report: htmlcov/index.html" >> "$PROJECT_ROOT/test-summary.txt"
    fi
    
    if [[ -f "$PROJECT_ROOT/test-results-unit.xml" ]]; then
        echo "  - Unit test results: test-results-unit.xml" >> "$PROJECT_ROOT/test-summary.txt"
    fi
    
    if [[ -f "$PROJECT_ROOT/test-results-integration.xml" ]]; then
        echo "  - Integration test results: test-results-integration.xml" >> "$PROJECT_ROOT/test-summary.txt"
    fi
    
    success "Test summary: test-summary.txt"
}

cleanup() {
    # Clean up any temporary files
    rm -f "$PROJECT_ROOT"/.coverage.*
    rm -rf "$PROJECT_ROOT"/.pytest_cache/
}

main() {
    # Default values
    RUN_UNIT=false
    RUN_INTEGRATION=false
    ENABLE_COVERAGE=false
    QUICK_MODE=false
    WATCH_MODE=false
    ENABLE_PARALLEL=true
    VERBOSE=false
    QUIET=false
    
    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --unit)
                RUN_UNIT=true
                shift
                ;;
            --integration)
                RUN_INTEGRATION=true
                shift
                ;;
            --coverage)
                ENABLE_COVERAGE=true
                shift
                ;;
            --quick)
                QUICK_MODE=true
                shift
                ;;
            --watch)
                WATCH_MODE=true
                shift
                ;;
            --parallel)
                ENABLE_PARALLEL=true
                shift
                ;;
            --no-parallel)
                ENABLE_PARALLEL=false
                shift
                ;;
            --verbose)
                VERBOSE=true
                shift
                ;;
            --quiet)
                QUIET=true
                shift
                ;;
            --help|-h)
                show_help
                exit 0
                ;;
            *)
                error "Unknown option: $1"
                show_help
                exit 1
                ;;
        esac
    done
    
    # If no specific test type selected, run all
    if [[ "$RUN_UNIT" == "false" && "$RUN_INTEGRATION" == "false" ]]; then
        RUN_UNIT=true
        RUN_INTEGRATION=true
    fi
    
    # Show banner
    echo -e "${BLUE}"
    cat << "EOF"
 _____ _            ____ _____ ___ 
|_   _(_)_ __  _   / ___|_   _|_ _|
  | | | | '_ \| | | |     | |  | | 
  | | | | | | | |_| |___  | |  | | 
  |_| |_|_| |_|\__, \____| |_| |___|
               |___/               
       Test Runner
EOF
    echo -e "${NC}"
    
    # Execute
    check_dependencies
    install_test_deps
    
    if [[ "$WATCH_MODE" == "true" ]]; then
        watch_mode
    else
        local start_time=$(date +%s)
        
        if run_tests; then
            local end_time=$(date +%s)
            local duration=$((end_time - start_time))
            
            generate_report
            success "All tests completed successfully in ${duration}s"
            
            if [[ "$ENABLE_COVERAGE" == "true" && -f "$PROJECT_ROOT/htmlcov/index.html" ]]; then
                echo ""
                log "Coverage report: file://$PROJECT_ROOT/htmlcov/index.html"
            fi
            
            cleanup
            exit 0
        else
            error "Some tests failed"
            cleanup
            exit 1
        fi
    fi
}

# Trap for cleanup on exit
trap cleanup EXIT

# Run main function
main "$@"