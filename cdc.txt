TinyCTI – Cahier des Charges Technique
Objectifs

TinyCTI est un framework léger de collecte et de publication d'indicateurs de compromission (IOCs) visant à centraliser des flux multiples de renseignements sur les menaces. Il doit ingérer, agréger et organiser des IOCs provenant de multiples sources et sous différents formats
docs.aws.amazon.com
, tout en les stockant de manière structurée et en éliminant les doublons pour faciliter leur exploitation par les équipes de sécurité
crowdstrike.com
. Les objectifs principaux sont :

    Modularité et extensibilité : Fournir une architecture modulaire permettant d’ajouter facilement de nouvelles sources de données (flux IOC) via une simple configuration ou par le développement de connecteurs (plugins Python) supplémentaires.

    Souplesse de configuration : Offrir une configuration permissive (de préférence en YAML) acceptant divers formats de flux (texte brut, CSV, JSON, STIX, TAXII v1/v2, RSS, etc.), avec la possibilité de préciser les détails de parsing (par ex. séparateur CSV, encodage, colonnes cibles).

    Gestion avancée des API keys : Permettre d’associer une ou plusieurs clés API par flux, avec détection automatique de la clé valide et rotation transparente des clés multiples afin d’éviter les limitations de taux ou quotas.

    Exécution simple : Pouvoir exécuter le framework en ligne de commande (CLI) pour intégration facile dans un scheduler (cron, systemd timer…), sans nécessité de serveur permanent. Une modification de configuration doit simplement nécessiter un redémarrage du programme (pas d’API d’administration en temps réel).

    Sortie et conservation des données : Stocker les IOCs collectés dans des fichiers de sortie séparés par type d’indicateur (adresses IP, noms de domaine, condensats SHA1, URL, etc.), en éliminant les doublons. Mettre en place un système de rotation et de conservation des fichiers basé sur des « buckets » de rétention nommés live, chaud, tiède, froid pour gérer le cycle de vie des IOCs.

    Journalisation détaillée : Produire des logs complets pour chaque flux traité (succès/échec de la collecte, nombre d’IOCs récupérés, source interrogée, etc.), en incluant les erreurs détaillées (trace complète en cas d’exception) et en notant l’heure de collecte, le parser utilisé ainsi que la clé API employée.

    Évolutivité vers une interface graphique : Concevoir l’architecture de telle sorte qu’il soit possible d’intégrer ultérieurement une interface web (par ex. une application Flask) permettant de configurer dynamiquement les flux et de visualiser les IOCs collectés ainsi que diverses statistiques, sans remise en question de l’architecture de base du framework.

    Code clair et maintenable : Adopter un design simple, cohérent et lisible du code. Le code source devra être bien commenté, facile à suivre et éviter les optimisations obscures ou une complexité architecturale inutile, afin de faciliter la maintenance et les contributions futures.

Architecture

L’architecture de TinyCTI est pensée pour être modulaire, découplant nettement la collecte des données, leur transformation, et leur stockage. Le framework s’articule autour de plusieurs composants principaux :

    Loader de configuration : Au lancement, TinyCTI charge un fichier de configuration (en YAML) décrivant les flux IOCs à collecter et leurs paramètres. Cette configuration centralisée pilote l’ensemble du comportement du framework (sources activées, réglages de parsing, clés API, etc.). Un redémarrage du programme suffit à recharger une configuration mise à jour.

    Gestionnaire de flux (orchestrateur) : Ce module principal parcourt les flux configurés et orchestre leur collecte. Il initialise pour chaque flux le connecteur approprié (voir section Modules) en fonction du type de source indiqué (texte, API JSON, flux STIX/TAXII, etc.), puis déclenche la récupération et le parsing des données. Il peut exécuter les collectes de manière séquentielle ou parallèle selon les besoins (par exemple, exécutions parallèles si de nombreux flux doivent être interrogés sans allonger la durée totale).

    Système de plugins (connecteurs) : L’architecture s’appuie sur un mécanisme de plugins pour gérer les différents types de sources en entrée. TinyCTI définit une interface standard que chaque connecteur de flux doit implémenter (par ex. une classe Python avec des méthodes collect() et parse()). Cela permet d’intégrer facilement de nouveaux types de flux en ajoutant un fichier plugin dans un répertoire dédié (par exemple plugins/). Cette approche de plugin est inspirée de frameworks existants comme ThreatIngestor, qui utilise une architecture à plugins distinguant les sources (input) et les opérateurs (output)
    pypi.org
    . Dans TinyCTI, les plugins de source prennent en charge la collecte (téléchargement des données brutes depuis la source) et le parsing (extraction des IOCs du format spécifique).

    Module de classification & déduplication : Une fois les IOCs extraits d’un flux, ce module se charge d’identifier leur type (IP v4, IP v6, domaine, URL, hash SHA1/MD5/SHA256, etc.) et d’éliminer les doublons éventuels avant l’écriture dans les fichiers de sortie. La classification peut s’appuyer sur des expressions régulières ou des bibliothèques existantes de détection d’IOCs. Chaque IOC est routé vers le fichier correspondant à son type uniquement s’il n’est pas déjà présent (une structure de données en mémoire ou une base d’indices simple pourra conserver l’historique des IOCs déjà vus pour chaque catégorie).

    Module de stockage des IOCs : Gère la création et la mise à jour des fichiers de sortie par type d’IOC. Il prend en charge l’ouverture des fichiers correspondant aux types détectés et l’ajout des nouveaux IOCs (après déduplication). Il implémente également la logique de rotation et archivage en fonction des catégories live/chaud/tiède/froid (voir section Stockage).

    Module de gestion des clés API : Si un flux nécessite une authentification par clé API (typiquement pour des services web de threat intelligence), ce composant s’occupe de sélectionner la clé appropriée à utiliser. La configuration pouvant associer plusieurs clés à une même source, le système détermine laquelle est valide ou la moins utilisée et la fournit au connecteur. En cas de détection d’une limite atteinte (par exemple une réponse indiquant un quota épuisé ou un code HTTP 429), le module bascule automatiquement sur une autre clé disponible, de manière transparente. Cette rotation évite les interruptions de collecte pour les flux soumis à des limitations strictes.

    Logger centralisé : L’architecture comprend un système de journalisation central, vers lequel chaque composant envoie des événements. Plutôt que de mélanger sorties standard et logs de chaque flux, un module dédié gère la consolidation des logs (écriture dans un ou plusieurs fichiers de log, avec différents niveaux de détail). Le logger garantit également que les erreurs ou exceptions non gérées dans un connecteur n’interrompent pas tout le processus global : elles sont capturées, loguées avec la trace, et le gestionnaire de flux peut passer au suivant.

L’ensemble de ces composants interagit de la façon suivante lors d’une exécution typique : le gestionnaire de flux charge la config, parcourt la liste de flux définis, pour chaque flux il instancie dynamiquement le plugin adéquat (en se basant sur le type/format configuré), utilise le module de gestion d’API pour insérer la clé si besoin, lance la collecte des données brutes, puis confie ces données au parser du plugin pour extraire les IOCs. Les IOCs extraits passent par la phase de classification/déduplication, puis sont transmis au module de stockage qui les ajoute aux fichiers. Enfin, le résultat de chaque flux (succès ou échec, nombre d’IOCs ajoutés, etc.) est envoyé au logger pour traçabilité. Ce découpage garantit une séparation claire des responsabilités et une facilité de maintenance, tout en assurant la robustesse du processus global (une erreur dans un plugin de flux n’empêchera pas les autres flux d’être traités).
Configuration

La configuration de TinyCTI sera centralisée dans un fichier au format YAML, choisi pour sa lisibilité et sa facilité à exprimer des structures de données complexes. Ce fichier de configuration décrit l’ensemble des flux IOCs à collecter ainsi que les paramètres propres à chacun. L’approche privilégiée est déclarative : en ajoutant ou modifiant une entrée dans le YAML, l’utilisateur peut activer un nouveau flux ou ajuster le comportement d’un flux existant, sans avoir à modifier le code.
Structure du fichier de configuration

Une section typique du fichier YAML pourrait ressembler à ceci :

feeds:
  - name: AbuseCH_URLhaus         # Nom du flux (description libre)
    type: csv                     # Type/format du flux (texte, csv, json, stix, taxii, rss, etc.)
    url: "https://urlhaus.abuse.ch/downloads/csv/"  # Adresse du flux (fichier ou API)
    delimiter: ","                # (Spécifique CSV) séparateur de colonnes
    encoding: "utf-8"             # (Optionnel) encodage du fichier source
    column: 2                     # (Spécifique CSV) colonne où se trouve l’IOC (peut accepter index ou nom)
    api_keys: []                  # Liste de clés API si requises (ici vide si non nécessaire)
    retention: "live"             # Catégorie de conservation (live/chaud/tiède/froid)
    enabled: true                 # Indicateur pour (dé)activer la collecte de ce flux

Chaque entrée sous feeds: définit un flux IOC à collecter. Les principaux champs de configuration incluront :

    name : un identifiant ou nom descriptif du flux (utile pour les logs et pour la clarté de la config).

    type : le type de source / format de données. Des valeurs possibles incluent text (texte brut ligne par ligne), csv, json, stix1 ou stix2 (pour des fichiers STIX 1.x XML ou STIX 2.x JSON), taxii (pour un flux via protocole TAXII v1/v2), rss (flux RSS/ATOM), etc. Ce champ est déterminant : il indique au framework quel plugin ou parser utiliser pour ce flux.

    url (ou chemin) : l’URL web du feed ou le chemin local du fichier contenant les IOCs. Selon le type, cela peut être un endpoint d’API REST renvoyant du JSON, l’adresse d’un serveur TAXII, l’URL d’un fichier CSV ou texte brut, etc. Pour un flux TAXII, la configuration pourra comporter plusieurs sous-champs (par ex. taxii_api_root, collection_id, username, password ou api_key selon le mécanisme d’authentification).

    Paramètres de format : des sous-champs permettant de préciser comment parser le contenu du flux, lorsque nécessaire. Par exemple, pour type: csv, on pourra spécifier delimiter (caractère séparateur, par ex. "," ou ";"), encoding (encodage du fichier, par défaut UTF-8), et column (le nom de colonne ou l’indice de colonne contenant l’IOC à extraire). De même, un type json pourrait accepter un champ json_path ou une clé spécifique à extraire (si le JSON renvoyé n’est pas une simple liste d’IOCs mais un objet plus complexe). L’idée est de rendre le parseur aussi configurable que possible sans avoir à écrire du code.

    api_keys : une liste de clés API (chaînes de caractères) pouvant être utilisées pour ce flux. Si le flux est public ou ne nécessite pas d’authentification, cette liste peut être vide ou absente. Si plusieurs clés sont fournies, le système saura les utiliser alternativement. La configuration peut également permettre de définir des alias ou des références vers un stock de clés sécurisé (par exemple, référencer une clé stockée dans une variable d’environnement ou un fichier séparé, afin de ne pas écrire directement la valeur dans le YAML en clair).

    retention : le tag de conservation associé à ce flux. Les valeurs possibles sont live, chaud, tiède, froid. Ce champ indique la nature du flux en termes de fraîcheur et conservation des IOCs (voir section Stockage pour le comportement détaillé). Par exemple, un flux de type live contiendra des IOCs très volatils (peu de conservation historique), tandis qu’un flux froid peut correspondre à des indicateurs plus pérennes ou archivés.

    enabled : un booléen pour activer/désactiver le flux sans supprimer sa configuration. Ceci permet de temporairement éteindre la collecte d’une source tout en la conservant dans le fichier pour la réactiver plus tard.

La configuration pourra éventuellement comporter d’autres sections globales, par exemple : un paramétrage du scheduler (fréquence d’exécution si le programme tourne en daemon ou si un mécanisme interne de timing est utilisé – néanmoins ici on privilégie l’utilisation d’outils externes comme cron, donc ce n’est pas crucial dans le cahier des charges), des paramètres globaux de logging (niveau de verbosité par défaut, emplacement des fichiers de log), ou de sortie (par exemple le répertoire racine où stocker les fichiers d’IOCs, par défaut quelque chose comme ./ioc/).

Le fichier YAML doit être validé au démarrage (détecter les erreurs de format ou de champs manquants) et des messages d’erreur clairs doivent être fournis en cas de mauvaise configuration. Une documentation du format (peut-être un schéma YAML ou simplement un exemple annoté) sera fournie pour guider les utilisateurs lors de l’ajout de nouveaux flux.
Modules (Plugins et Composants Internes)

Afin de respecter l’exigence de modularité, TinyCTI sera organisé en modules distincts correspondant aux responsabilités fonctionnelles. Voici les principaux modules et comment ils interagissent :

    Module de Connecteurs (Plugins de sources) : Chaque type de flux est pris en charge par un plugin spécifique. Par exemple, on pourra avoir un plugin TextFeed pour les sources texte brut, un plugin CSVFeed pour les CSV, JSONFeed pour des API JSON, StixFeed pour les fichiers STIX 1.x/2.x, TaxiiFeed pour interroger un serveur TAXII, ou encore RssFeed pour les flux RSS/Atom. Ces plugins résident dans le répertoire plugins/ du projet et sont découverts dynamiquement par TinyCTI (via un mécanisme d’entrée de module Python ou en important tous les modules du dossier). Chacun implémente les méthodes nécessaires : typiquement collect() (pour récupérer les données brutes de la source) et parse(raw_data) (pour extraire une liste d’IOCs depuis les données brutes). Cette architecture plugin permet d’étendre les capacités du framework sans modifier le cœur : pour ajouter un nouveau type de flux, il suffit de développer un plugin suivant le modèle requis et de l’ajouter. Le cœur du système n’a pas besoin de connaître les détails de chaque format à l’avance, il ne fait qu’appeler le plugin adapté en fonction du type indiqué dans la config.

    Module de Parsing générique : En complément des plugins spécialisés, TinyCTI inclut des outils génériques d’extraction d’IOCs, notamment pour détecter les IOCs dans des contenus textuels non structurés. Par exemple, un plugin TextFeed qui récupère une page web ou un texte libre peut s’appuyer sur des expressions régulières ou une bibliothèque d’extraction (telle que ioc-finder ou iocextract) pour repérer les indicateurs (adresses IP, URLs, noms de domaine, hachages, etc.) au sein du texte. Ces fonctions de parsing génériques peuvent être partagées entre plugins (éviter la duplication de logique d’extraction).

    Module de Gestion d’API (Client HTTP) : Pour les flux web (HTTP/HTTPS), un module dédié gère les requêtes réseau. Il intègre la gestion des clés API (en ajoutant les en-têtes ou paramètres requis à la requête), la gestion des erreurs réseau (timeouts, codes d’erreur HTTP) et éventuellement des mécanismes de retry exponentiel en cas d’échec temporaire. Ce module agit comme un client HTTP/HTTPS centralisé, offrant aux plugins une interface simple pour faire des requêtes (par exemple une fonction fetch_url(url, headers, params) qu’un plugin peut appeler sans se soucier des détails d’authentification ou de gestion d’erreur).

    Module de Stockage (IOCs Writer) : Responsable d’enregistrer les IOCs extraits dans les fichiers appropriés. Il offre des fonctions telles que write_ioc(ioc_type, ioc_value, retention_bucket) qui ajoutent l’IOC donné dans le fichier correspondant à son type (par ex. ipv4.txt pour les adresses IPv4, domain.txt pour les domaines, etc.), dans la zone de stockage correspondant au bucket de rétention spécifié. Ce module gère aussi la déduplication de manière persistante : avant écriture, il vérifie (par exemple en mémoire ou via un index sur disque) si l’IOC existe déjà dans le fichier cible ou a déjà été vu récemment, pour éviter d’écrire des doublons. En cas de duplicat, il peut soit ignorer l’écriture, soit éventuellement mettre à jour un timestamp d’observation (si on souhaite garder une notion de « vu à nouveau le… »).

    Module de Rotation & Archivage : Relié au module de stockage, ce composant applique la politique de rétention. Il peut être déclenché à intervalles réguliers ou après chaque collecte. Son rôle est de déplacer ou purger les IOCs anciens selon le schéma live/chaud/tiède/froid. Par exemple, on peut implémenter la logique suivante : les IOCs nouvellement ajoutés résident dans les fichiers « live ». Au bout d’un certain délai (configurable, par ex. 24h), un IOC est déplacé du fichier live vers le fichier chaud correspondant. Après une période additionnelle (ex. plusieurs jours), il passe dans tiède, puis finalement dans froid (qui pourrait être un fichier d’archive compressé ou un stockage longue durée). Ce module de rotation peut soit maintenir quatre fichiers distincts par type (par ex. ipv4_live.txt, ipv4_chaud.txt, etc.), soit gérer un marquage interne des entrées avec leur catégorie et effectuer le transfert entre fichiers. L’approche par fichiers séparés par bucket est plus simple à implémenter et à consulter. Les durées associées à chaque niveau (live->chaud, chaud->tiède, tiède->froid) seront définies dans la configuration globale ou dans la config de chaque flux (on pourrait permettre de surcharger les durées par flux si nécessaire).

    Module de Logging : Centralise la journalisation. Il peut s’agir simplement de l’utilisation de la bibliothèque standard de logging Python avec une configuration adaptée (fichier de log rotatif, format commun), ou d’un module custom pour formater les messages. Chaque action notable du système produit un log à un niveau approprié (INFO pour les actions normales comme « X IOCs écrits depuis tel flux », WARNING pour des situations anormales récupérées, ERROR pour des échecs, DEBUG pour des informations de diagnostic détaillées). Ce module s’assure aussi que les clés API sensibles ne sont pas exposées en clair dans les logs (par ex. ne pas loguer l’URL complète si elle contient une clé, ou masquer partiellement les clés lorsqu’on loggue leur utilisation). Il peut également tenir un journal par flux en plus d’un journal global : par exemple un fichier de log par source nommée, afin de pouvoir isoler facilement l’historique d’un flux particulier lors du débogage.

En résumé, l’architecture modulaire de TinyCTI se traduit par un découpage en modules/plugins spécialisés, faiblement couplés, communiquant via des interfaces claires. Cela facilite l’ajout de nouvelles fonctionnalités (nouveau type de flux, nouveau format d’export, etc.) en minimisant l’impact sur le reste du système.
Flux (Sources de données IOC)

TinyCTI doit supporter un large éventail de formats de flux de renseignements sur les menaces, afin de pouvoir s’adapter à la variété des sources existantes dans l’écosystème CTI. Pour chaque type de flux, des particularités de traitement sont à prendre en compte :

    Flux Texte Brut : Il s’agit de sources où les IOCs sont fournis sous forme de texte libre ou de listes simples (par exemple une liste d’IP malveillantes, une page web contenant des indicateurs noyés dans du texte). Le plugin associé récupère le contenu (par une requête HTTP GET typiquement) et applique des expressions régulières ou un extracteur d’IOCs pour extraire les indicateurs. Chaque ligne peut être considérée comme un IOC potentiel (avec filtrage par format attendu). L’extraction portera attention à éliminer d’éventuels faux positifs (par ex. un numéro pouvant ressembler à une IP) en validant le format. Ce mode texte brut est permissif et polyvalent, utilisable pour des flux simples (ex: listes noires publiques hébergées sur Pastebin, GitHub Gist, etc.).

    Flux CSV : De nombreuses sources publient des IOCs sous forme de fichier CSV (Comma-Separated Values) ou équivalent (TSV, etc.). TinyCTI doit permettre de lire ces fichiers en prenant en compte : le séparateur (virgule, point-virgule, tabulation…), l’encodage (UTF-8, latin-1…), une éventuelle ligne d’en-tête, et surtout la colonne où se trouvent les IOCs. Via la configuration (champs delimiter, column, etc.), on pourra adapter le parser générique CSV. Le plugin CSV lira le fichier ligne par ligne (en utilisant par exemple Python csv.reader ou pandas pour les cas complexes) et en extraira la valeur de la colonne cible. Si nécessaire, il pourra aussi appliquer une transformation sur la valeur (par ex. trim des espaces, conversion de case, ou extraction d’une partie de champ si le CSV a plusieurs IOCs concaténés). Une fois les IOCs extraits, la suite du traitement (classification par type, déduplication) s’applique.

    Flux JSON (API REST) : Ici la source est une API ou un fichier JSON contenant des IOCs. Le format JSON peut varier fortement d’un fournisseur à l’autre. Parfois, le JSON est une simple liste de valeurs (ex: ["1.2.3.4","5.6.7.8",...]), mais souvent il est plus riche (liste d’objets avec divers champs). La configuration pourrait permettre de spécifier une clé JSON particulière à extraire (ex: json_key: "indicator"), ou un chemin d’accès (ex: json_path: "$.indicators[*].value" en utilisant la syntaxe JSONPath). Le plugin JSON utilisera ces indications pour parcourir la structure JSON et récupérer les valeurs correspondantes aux IOCs. S’il n’y a pas de configuration spécifique, le plugin peut tenter automatiquement de détecter les IOCs dans tout le JSON (en recherchant des motifs d’IP, de domaines, etc., mais cela peut introduire de faux positifs si le JSON contient d’autres données). On privilégiera une extraction ciblée via configuration pour les sources JSON structurées connues.

    Flux STIX : STIX (Structured Threat Information eXpression) est un langage standardisé pour représenter des informations de cybermenace de façon structurée
    flare.io
    . TinyCTI doit pouvoir ingérer des fichiers ou collections STIX. STIX 1.x était généralement en XML, STIX 2.x est en JSON; il faudra gérer potentiellement les deux (d’où le type pouvant être stix1 ou stix2). Le plugin STIX s’appuiera idéalement sur des bibliothèques existantes (par ex. stix2 en Python pour parser du JSON STIX 2, ou cybox/stix pour STIX 1). Il extrait les observables ou indicateurs contenus dans les objets STIX (ex: objets de type Indicator ou observables d’adresses, fichiers…). L’avantage du STIX est de fournir du contexte et des relations, mais dans TinyCTI on se concentrera sur l’extraction des observables concrets (IPs, domaines, URL, hashes) pour les ajouter aux fichiers d’IOC. On notera que STIX pouvant contenir différents types d’indicateurs, le plugin devra parcourir l’arborescence et collecter tous les attributs de type observable. La prise en charge de STIX 2 (JSON) est prioritaire étant donné qu’il s’agit de la version moderne standardisée, mais la compatibilité avec d’anciens flux STIX 1.x pourrait être un plus.

    Flux TAXII (v1/v2) : TAXII (Trusted Automated eXchange of Intelligence Information) est un protocole d’échange de renseignements cyber automatisé et sécurisé
    flare.io
    . De nombreux fournisseurs offrent des collections d’IOCs via un serveur TAXII. TinyCTI doit pouvoir se connecter à un serveur TAXII version 1 ou 2, authentifié si nécessaire, pour extraire les indicateurs. Un plugin TaxiiFeed gérera cela, possiblement en s’appuyant sur une bibliothèque spécialisée (comme taxii2-client pour TAXII 2.x). La configuration devra fournir les informations nécessaires : l’URL racine de l’API TAXII (api_root), l’ID de collection à interroger, ainsi que les credentials (soit une clé API, soit un couple utilisateur/mot de passe, selon le fournisseur). Pour TAXII v1 (XML SOAP), le support peut être plus complexe, mais on peut restreindre le périmètre aux TAXII v2 (REST JSON) qui sont plus récents, tout en gardant la porte ouverte pour v1 via un plugin spécifique si besoin. Le plugin effectuera les requêtes (par ex. via GET/POST sur les endpoints /collections/{id}/objects pour TAXII 2) et récupérera les objets STIX qu’il contient, qu’il passera ensuite au parseur STIX mentionné ci-dessus pour en extraire les IOCs.

    Flux RSS/ATOM : Certains flux CTI sont disponibles via des fils RSS ou Atom (par exemple des blogs sécurité ou des rapports de nouvelles menaces sous forme de flux d’articles). Un plugin RSS ira récupérer le flux XML RSS, l’analysera (via une bibliothèque comme feedparser) et extraira le contenu de chaque item. La difficulté ici est que le flux RSS n’est pas un contenant d’IOC en soi, mais plutôt de l’actualité. Toutefois, si la demande inclut RSS, on peut supposer qu’il existe des flux RSS listant directement des IOC (ou contenant des IOCs dans la description). Le plugin pourrait donc soit extraire tout texte des entrées RSS et y détecter des IOCs via les mêmes regex que pour texte brut, soit être utilisé pour centraliser des sources d’information (pas uniquement des indicateurs). Dans le cadre de TinyCTI, on s’en tiendra à l’extraction d’IOCs si présents dans le contenu RSS (par exemple certains CERT publient des flux RSS avec les dernières URL de phishing détectées, etc.).

Chaque type de flux bénéficie donc d’un traitement adapté, mais grâce à l’architecture par plugins, la plupart de ces détails sont encapsulés. Du point de vue de la configuration utilisateur, ajouter un flux d’un certain type consiste à fournir les bons paramètres, le système se chargeant de sélectionner le bon plugin et de suivre la bonne routine de parsing.

Enfin, l’ajout de nouveaux formats non listés ici devra être possible via l’extensibilité du système. Par exemple, si un nouveau standard de partage d’IOC émerge ou si on souhaite intégrer une base de données locale, il suffira de développer un nouveau plugin ou module d’ingestion respectant l’interface requise, sans modification drastique du core. La documentation du projet expliquera comment créer de tels plugins.
Journalisation (Logs)

Un logging avancé est crucial pour un outil de cette nature, afin de garantir la traçabilité des opérations et de faciliter le diagnostic en cas de problème. TinyCTI produira des journaux (logs) détaillés couvrant plusieurs dimensions :

    Log par exécution et par flux : À chaque lancement (que ce soit via la CLI manuellement ou via un scheduler automatique), le framework génèrera un log global résumant le déroulement de la session. De plus, pour chaque flux configuré, une section de log détaillée sera enregistrée. On y trouvera notamment la timestamp du début de traitement du flux, le nom du flux (tel que défini dans la config), et le résultat de la tentative de collecte. En cas de réussite, le log indique le nombre d’IOCs extraits et ajoutés (par type éventuellement). En cas d’échec, le log mentionne la nature de l’erreur (par ex. « échec HTTP 404 : ressource non trouvée », « erreur de parsing JSON », etc.).

    Niveau de détail et traçabilité des erreurs : Le logger enregistrera non seulement un message d’erreur mais également la trace complète (stack trace) de l’exception en mode debug ou dans un fichier séparé dédié aux erreurs. Ainsi, si un plugin plante à cause d’un format inattendu, le développeur ou l’administrateur pourra retrouver exactement à quelle ligne et pourquoi (Exception Python, message associé) cela s’est produit. Cette exigence permet une résolution plus rapide des bugs.

    Informations contextuelles : Chaque entrée de log inclura des informations contextuelles utiles pour comprendre l’état du système lors de l’événement. Par exemple, lors de la collecte d’un flux, le log pourra contenir : l’heure de début et de fin de la collecte, la durée prise, la taille des données brutes récupérées (ex: « 500 Ko reçus »), le parser/ plugin utilisé pour ce flux, et la clé API utilisée le cas échéant (en la désignant de façon non compromettante – par exemple en indiquant un identifiant ou les 4 derniers caractères de la clé pour la reconnaître sans l’exposer intégralement).

    Logs de rotation/archivage : Le système de gestion des buckets de rétention produira aussi des logs. Par exemple, s’il déplace des IOCs du bucket live vers chaud, il notera combien d’entrées ont été déplacées et à quel moment. En cas de suppression (si la politique prévoit éventuellement de purger les IOCs trop vieux en froid), cela sera également logué. Ceci permet de suivre l’évolution du volume de données et de vérifier que la rotation opère comme prévu.

    Format et emplacement des journaux : Les logs seront écrits dans des fichiers texte (à moins qu’une intégration avec un système de log centralisé soit souhaitée ultérieurement). Un fichier de log principal (ex: tinycti.log) contiendra chronologiquement tous les événements de haut niveau de chaque exécution. On peut envisager de le faire tourner (log rotation) quotidiennement ou selon une taille maximale, pour éviter une croissance infinie. En complément, des logs séparés par flux (logs/flux_nom.log) pourraient enregistrer l’historique propre à chaque source au fil du temps. Cela simplifiera la consultation de l’historique d’un flux donné (utile par exemple pour voir si un flux particulier échoue fréquemment, ou combien d’IOCs il fournit en moyenne).

    Verbosity configurable : Le niveau de verbosité sera configurable (par exemple via la config YAML ou une option CLI). En mode normal, on pourra limiter aux informations importantes (succès/échec, compte d’IOCs). En mode debug, activer des logs très détaillés (y compris requêtes effectuées, données reçues tronquées, etc.). Ce réglage permet d’utiliser TinyCTI en production avec des logs concis, ou en phase de test/intégration avec des logs très verbeux pour diagnostiquer les moindres détails.

Exemple de séquence de log (imaginaires) pour illustrer le niveau de détail attendu :

[2025-06-27 20:26:30] INFO  ─ Lancement de TinyCTI v1.0
[2025-06-27 20:26:30] INFO  ─ Chargement de la configuration: 5 flux définis.
[2025-06-27 20:26:30] INFO  ─ Début de collecte du flux "AbuseCH_URLhaus" (type=csv, retention=live)
[2025-06-27 20:26:31] INFO  ─ AbuseCH_URLhaus: 120 IOCs extraits du CSV (dont 100 nouveaux, 20 doublons ignorés) – [IPs:80, URLs:40]
[2025-06-27 20:26:31] INFO  ─ Fin de collecte du flux "AbuseCH_URLhaus" (succès en 0.8s)
[2025-06-27 20:26:31] INFO  ─ Début de collecte du flux "OTX_PulseAPI" (type=json, retention=chaud)
[2025-06-27 20:26:32] ERROR ─ OTX_PulseAPI: Échec lors de la requête HTTP (401 Unauthorized) – Clé API utilisée: keyID 2
[2025-06-27 20:26:32] WARN  ─ OTX_PulseAPI: Nouvelle tentative avec rotation de clé API (keyID 3)
[2025-06-27 20:26:33] INFO  ─ OTX_PulseAPI: 45 IOCs extraits du JSON (tous nouveaux) – [IPs:30, Domaines:15]
[2025-06-27 20:26:33] INFO  ─ Fin de collecte du flux "OTX_PulseAPI" (succès en 2.1s, après rotation de clé)
...
[2025-06-27 20:26:35] INFO  ─ Rotation des buckets: 50 IOCs déplacés de live à chaud, 200 de chaud à tiède, 100 purgés de froid (>180 jours)
[2025-06-27 20:26:35] INFO  ─ Exécution terminée. Total IOCs nouveaux ajoutés: 145 (IPs:110, Domaines:15, URLs:40, Hashes:0)

Ce pseudo-extrait illustre la granularité attendue : on voit la progression par flux, le handling d’une erreur avec rotation de clé API, les statistiques d’extraction et la rotation finale.

En somme, la journalisation de TinyCTI doit offrir une visibilité complète sur ce que fait le framework, flux par flux, étape par étape. Cela répond à la fois aux besoins opérationnels (savoir quand et combien d’IOCs sont importés, repérer les problèmes rapidement) et aux besoins de développement (débuggage facilité grâce aux traces détaillées).
Stockage et Rétention des IOCs

La gestion du stockage des IOCs est un aspect central de TinyCTI, car elle conditionne la manière dont les données collectées seront exploitées ultérieurement. Le cahier des charges impose une séparation des IOCs par type et une gestion de la rétention via les catégories live/chaud/tiède/froid. Voici comment cela se traduit techniquement :

    Organisation par type d’IOC : Pour chaque catégorie d’indicateur de compromission, TinyCTI maintiendra un fichier (ou ensemble de fichiers) distinct. Par exemple, on pourra définir les fichiers principaux suivants dans un répertoire de sortie (par ex. le dossier ioc/) :

        ipv4.txt pour les adresses IPv4

        ipv6.txt pour les adresses IPv6

        domain.txt pour les noms de domaine

        url.txt pour les URLs

        sha1.txt, md5.txt, sha256.txt (ou un fichier hash.txt avec indication du type de hash si nécessaire) pour les condensats de fichiers

        éventuellement d’autres types si requis (adresses email malveillantes, clés de registre, etc., selon l’extension du domaine d’application, mais les types listés couvrent les IOCs réseau et fichier les plus courants).

    Ces fichiers contiennent chacun la liste unique des IOCs de ce type connus du système, dans le périmètre de rétention défini (voir ci-après). L’avantage de séparer par type est de faciliter l’exploitation par d’autres outils : par exemple, une équipe défense peut directement prendre le fichier ipv4.txt et l’importer dans un firewall ou SIEM pour mise en liste noire, etc., sans avoir à filtrer parmi d’autres types.

    Élimination des doublons : Le système de stockage intégrera la déduplication pour éviter les redondances. Si un même IOC est fourni par plusieurs flux ou réapparaît plusieurs fois dans le temps, il ne doit figurer qu’une fois dans le fichier correspondant (sauf si on choisit de tracer la fréquence, mais ce n’est pas demandé ici). La déduplication peut être gérée en mémoire pendant l’exécution (par exemple via un set Python alimenté au fur et à mesure) combiné à la persistance : typiquement, avant d’écrire un IOC dans le fichier, TinyCTI peut vérifier rapidement s’il y est déjà présent. Une optimisation possible est de maintenir un index (par ex. une base SQLite ou un simple fichier log des ajouts) pour éviter de relire de gros fichiers texte à chaque fois. Cependant, étant donné que la volumétrie d’IOCs peut être élevée, il faudra veiller à l’efficacité de cette étape. On peut imaginer que chaque fichier type soit trié ou que les IOCs soient stockés avec un hash pour comparaison rapide. Dans un premier temps, une approche simple (lecture du fichier en mémoire au démarrage pour construire un set de déjà-vus, puis opérations en RAM) peut suffire, avec l’idée d’optimiser si la taille devient trop grande.

    Buckets de rétention live/chaud/tiède/froid : Ces termes font référence à des niveaux de fraîcheur des données, sur le modèle des politiques de rétention des logs ou des données temporelles. TinyCTI implémentera ce concept de la manière suivante :

        Live : c’est le jeu de données le plus récent et actif. On peut interpréter live comme « données en temps quasi-réel ». Concrètement, les fichiers live contiennent les IOCs collectés très récemment, par exemple ceux des dernières 24 heures (le seuil exact peut être ajusté). Ce sont ces IOCs qui sont supposés être les plus pertinents à court terme (par ex. des IP d’attaque en cours, des URLs de phishing très récents, etc.). Le système peut choisir de mettre à jour les fichiers live de façon à ne contenir que les IOCs récents en supprimant ou déplaçant ceux qui dépassent l’âge seuil du live.

        Chaud : ce niveau regroupe les IOCs récents, mais un peu moins que live (par exemple de 1 à 7 jours). Les IOCs passent du live au chaud lorsqu’ils atteignent un certain âge. Dans les fichiers chaud, les IOCs sont encore relativement à jour et susceptibles d’être utiles pour des analyses récentes ou des blocages, mais ils ne sont plus tout frais.

        Tiède : correspond à des IOCs plus anciens (par ex. de 1 semaine à quelques mois). Ils ont quitté le statut chaud pour un stockage moins fréquemment accédé. Ces IOCs sont conservés pour historique ou pour corrélation (par exemple, investiguer une alerte pourrait nécessiter de savoir si une IP était malveillante il y a 2 mois).

        Froid : c’est l’archive longue durée. Les IOCs qui dépassent le seuil du tiède sont déplacés en froid. On peut envisager que les buckets froid soient éventuellement stockés de manière compressée ou dans un format d’archive (par ex. un fichier par trimestre, ou une base de données d’archivage) pour ne pas alourdir indéfiniment des fichiers texte. Les données froides sont utiles pour de la rétro-analyse ou de la recherche historique, mais probablement pas pour une utilisation directe dans des outils temps-réel (car ces IOCs sont possiblement obsolètes ou inactifs).

    En pratique, l’implémentation pourrait créer quatre sous-répertoires dans le dossier IOCs : live/, chaud/, tiede/, froid/ (ou bien préfixer les fichiers, ex: ipv4_live.txt, etc.). À chaque cycle de rotation (par ex. exécuté quotidiennement), le module de rotation déplacera les entrées éligibles d’un niveau au suivant. Par exemple, un IOC qui était dans live/ipv4.txt hier et qui n’a pas été mis à jour aujourd’hui sera déplacé dans chaud/ipv4.txt. Ce déplacement peut être un append dans le fichier de destination puis suppression de l’ancien fichier, ou plus simplement on peut recomposer les fichiers à chaque rotation.

    Chaque flux ayant un tag de rétention dans la config, on peut traiter différemment les IOCs issus de flux différents si voulu. Toutefois, pour simplifier, on peut considérer que le tag sert surtout à décider dans quel bucket initial un nouveau IOC va être placé et la politique de durée associée. Par exemple, un flux taggé froid pourrait signifier que ses IOCs sont dès le départ considérés comme longue durée (peut-être parce que c’est un feed de réputation stable), donc on pourrait les stocker directement dans la section froid sans les faire transiter par live/chaud. Inversement, un flux live alimentera le bucket live en priorité. Cette interprétation reste à affiner, mais ce serait un moyen de personnaliser la rétention par flux.

    Accès concurrent et verrouillage : Le système de stockage devra gérer le fait que plusieurs flux peuvent, lors d’une même exécution, vouloir écrire dans le même fichier type (par ex. deux flux fournissant des IPs malveillantes alimentent tous deux ipv4.txt). S’ils sont traités séquentiellement, ce n’est pas un problème majeur (chaque écriture se fait l’une après l’autre). Si le traitement est parallèle, il faudra implémenter un mécanisme de verrou (file lock) lors de l’accès en écriture à un fichier pour éviter des collisions ou corruptions. On peut aussi choisir de sérialiser les écritures (mettre en file les IOCs extraits puis un seul thread fait les écritures). Quoi qu’il en soit, l’intégrité des fichiers de sortie doit être assurée même en cas de multiples producteurs.

En résumé, la stratégie de stockage de TinyCTI vise à faciliter l’usage opérationnel (fichiers par type prêts à l’emploi) tout en maîtrisant la volumétrie par un cycle de vie des données. Un IOC traverse les étapes de fraîcheur depuis live jusqu’à l’archive froid, reflétant ainsi sa pertinence décroissante dans le temps, et permettant de limiter la taille des listes actives. Cette approche assure que les équipes sécurité disposent d’une liste concise des menaces actuelles tout en ayant la possibilité de consulter l’historique au besoin.
Extensibilité et Évolutions Futures

Dès sa conception, TinyCTI doit être pensé pour s’adapter aux évolutions et accepter des extensions, sans nécessiter de refonte majeure. Plusieurs axes d’extensibilité sont identifiés :

    Ajout de nouveaux connecteurs (plugins) : Comme évoqué précédemment, l’architecture modulaire facilite l’ajout de nouvelles sources. Pour intégrer un nouveau flux de menace qui n’entre pas exactement dans les formats supportés, il suffira de développer un nouveau plugin Python. Par exemple, si demain un fournisseur propose un gisement d’IOCs via un gRPC stream, un plugin spécifique pourra être écrit pour se connecter à ce stream et extraire les IOCs, puis branché dans TinyCTI. La seule contrainte sera de respecter l’interface (les méthodes standard de collecte/parsing). La configuration pourra alors utiliser un type correspondant (éventuellement le plugin pourra s’enregistrer sous un nom de type). Une documentation pour les développeurs de plugins sera prévue, détaillant comment créer un nouveau module et l’intégrer (par ex. en l’ajoutant dans plugins/__init__.py ou via un mécanisme d’entry points pkg_resources). Ce modèle de plugin est courant dans les outils CTI et a prouvé sa souplesse
    pypi.org
    .

    Nouveaux formats d’export : Actuellement, TinyCTI se concentre sur l’export des IOCs dans des fichiers texte locaux. Mais on peut imaginer que dans le futur, on veuille publier les IOCs vers d’autres systèmes (puisque l’intitulé parle de “publication” d’IOCs). Par exemple, pousser les IOCs vers une base de données centralisée, vers un MISP (Malware Information Sharing Platform) ou un autre Threat Intelligence Platform (TIP), ou même déclencher des API d’un firewall. L’architecture devrait donc prévoir la possibilité d’ajouter des modules de sortie (analogue aux “operator plugins” de ThreatIngestor). Cela pourrait se traduire par un pipeline en plusieurs étapes : ingestion (source) -> transformation -> sortie(s). Bien que hors du périmètre immédiat, s’assurer que le code n’est pas figé à uniquement « écrire dans des fichiers » est un point d’extensibilité. Par exemple, structurer le module de stockage pour qu’il puisse avoir plusieurs implémentations (au lieu d’écrire dans des .txt, on pourrait le remplacer ou le compléter par un writer vers une base SQLite ou un dépôt cloud).

    Interface graphique future : L’une des demandes est de préparer l’ajout d’une interface graphique (web UI) ultérieure. Cela signifie qu’il faut anticiper la séparation entre la logique métier du framework et la couche présentation/contrôle qu’une UI fournirait. Concrètement, on peut veiller à :

        Isoler la gestion de configuration dans une classe ou module que l’UI pourrait appeler (par ex. avoir des fonctions load_config() et save_config() pouvant être invoquées depuis une application Flask pour lire/écrire la config YAML, éventuellement avec verrou si le programme tourne en même temps).

        Prévoir que le cœur du système (collecte des flux) puisse être déclenché non seulement via la CLI mais aussi via une fonction callable. Par exemple, avoir une fonction run_collection() ou un scheduler interne que l’UI pourrait piloter. Même si on n’implémente pas l’API runtime maintenant, le code peut être écrit de manière à ne pas tout faire dans le if __name__=="__main__": du script CLI, mais à avoir des fonctions réutilisables.

        Stocker les résultats de manière accessible : les fichiers texte conviennent, mais une UI pourrait bénéficier de données plus structurées (ex: un léger sqlite ou au moins du JSON) pour afficher les statistiques ou les IOCs. Sans aller jusqu’à le faire, on peut prévoir éventuellement d’enregistrer en parallèle un petit index des IOCs avec méta-données (source d’origine, date d’ajout, etc.) dans une base. Ce n’est pas requis explicitement, mais ce genre de structuration faciliterait une interface qui affiche par exemple « tel IOC provient de tel flux le tant ».

    Paramétrage modulaire : L’extensibilité passe aussi par rendre le plus de choses possible configurables plutôt que figées en dur. Par exemple, les règles de rotation live/chaud/tiède/froid (durées, etc.) devraient être dans la config ou dans un fichier de paramètres, afin de pouvoir être ajustées en fonction des besoins sans changer le code. De même pour des choses comme les formats reconnus pour classer les IOCs (regex utilisées, etc.), on pourrait imaginer un fichier de config des types. Ainsi, si on veut ajouter la détection d’un nouvel indicateur type (ex: adresse Bitcoin, ou autre), on pourrait ajouter son regex et son fichier de sortie via config. Cela renforce la flexibilité du système.

    Performance et scalabilité : Si à l’avenir le nombre de flux augmente considérablement ou la volumétrie des IOCs explose, le design actuel (basé sur fichiers textes et exécution script) pourrait montrer des limites. Cependant, l’architecture modulaire permettra d’identifier les points à améliorer (par exemple remplacer les fichiers par une base plus efficiente, paralléliser davantage la collecte, etc.) sans remettre en cause l’ensemble. L’extensibilité concerne donc aussi la capacité à faire évoluer l’outil pour des charges plus importantes. En gardant le code clair et en évitant les optimisations prématurées, on s’assure de pouvoir refactoriser des portions de code critiques si besoin (par exemple, remplacer la déduplication naïve par un usage de structures de données plus performantes).

En résumé, TinyCTI est conçu non comme un produit figé, mais comme une plateforme évolutive. Que ce soit pour intégrer de nouveaux flux, modifier la manière de stocker/publier les IOCs, ou ajouter une interface utilisateur, le framework fournit des points d’extension clairs et une séparation des préoccupations qui rend ces évolutions possibles sans casse. Cette philosophie garantit que TinyCTI pourra grandir et s’adapter aux besoins futurs des utilisateurs et de l’écosystème CTI.
Sécurité

Bien qu’il s’agisse principalement d’un outil interne de collecte, TinyCTI doit respecter un certain nombre de bonnes pratiques de sécurité dans sa conception et son utilisation :

    Protection des clés API : Les clés API utilisées pour interroger des services tiers sont souvent sensibles. Il convient de les protéger autant que possible. Dans la configuration, si elles sont stockées en clair dans le fichier YAML, il faudra conseiller de restreindre les permissions du fichier (lecture seulement pour l’utilisateur du service). Une amélioration possible est de permettre de chiffrer les clés ou de les fournir via des variables d’environnement ou un store sécurisé, afin qu’elles ne résident pas en clair sur le disque. Par ailleurs, comme mentionné en section Journalisation, les clés ne doivent jamais apparaître en clair dans les logs ou l’interface (le cas échéant). Si une erreur d’API survient, le message de log se limitera à indiquer par ex. « Clé API invalide ou expirée » sans imprimer la clé concernée. La rotation de clés doit également se faire de façon sûre (ne pas exposer la clé abandonnée).

    Sécurité des connexions réseau : TinyCTI va se connecter à de multiples sources externes (HTTP/S). Il faut veiller à utiliser des connexions sécurisées (HTTPS) autant que possible, et vérifier les certificats (pas de désactivation de la vérification SSL sauf si explicitement demandé pour un flux non sécurisé). En cas de flux utilisant TAXII ou autres protocoles, s’assurer que les bibliothèques respectent bien les bonnes pratiques de chiffrement. Si des authentifications basiques sont utilisées (user/pass), encourager l’utilisation de TLS pour éviter la transmission en clair de ces infos.

    Validation des données entrantes : Les données provenant de sources externes peuvent être malformées, ou dans le pire cas malicieuses. Un flux compromis pourrait envoyer une charge inhabituellement lourde ou un contenu conçu pour exploiter une vulnérabilité dans un parser. Il faudra donc coder les parsers de façon robuste (utiliser des bibliothèques éprouvées pour JSON, CSV, XML, etc., qui gèrent les cas pathologiques). Limiter par exemple la taille maximale des contenus téléchargés (pour éviter de saturer la mémoire en cas de boucle infinie ou fichier trop gros). Ne pas exécuter de code arbitraire sur la base des données reçues (par ex. éviter d’eval du contenu JSON, toujours le parser correctement). Pour STIX/XML, attention aux attaques de type XML External Entity (XXE) : il faudra désactiver la résolution d’entités externes lors du parsing XML pour éviter des exfiltrations accidentelles.

    Isolement du processus : Il est recommandé d’exécuter TinyCTI avec des droits limités sur la machine. Par exemple, l’utilisateur système dédié à ce service ne devrait avoir accès qu’au répertoire nécessaire (pas de privilèges root, etc.). Ainsi, même si une source malveillante arrivait à faire exécuter du code via une faille, l’impact serait contenu. La documentation encouragera ce mode d’exécution. De plus, TinyCTI ne nécessitant pas d’ouverture de port réseau entrant (pas de serveur en écoute), la surface d’attaque à distance est limitée aux dépendances tierces (bibliothèques) et aux flux externes consommés.

    Sécurité de l’interface future : Bien que non implémentée dans cette version, l’éventuelle interface Flask future devra être protégée par authentification, et possiblement un contrôle des accès (lecture seule vs admin). Il est simplement noté ici qu’on devra y penser lors de son développement. En attendant, aucune interface interactive n’étant exposée, le principal vecteur reste la CLI.

    Intégrité des données : Le système de rotation et stockage doit s’assurer de ne pas perdre de données pendant les déplacements entre buckets. Une mesure possible est d’effectuer des copies suivies de vérifications plutôt que des coupures brutales, ou de conserver des sauvegardes. Ce n’est pas tant une question de sécurité que de fiabilité, mais c’est lié à la protection contre la corruption de données (éventuellement due à un bug ou incident lors d’une rotation). On peut logguer un résumé de contenu avant/après rotation pour valider que le nombre d’IOCs correspond.

    Mises à jour et dépendances : TinyCTI s’appuiera sur des bibliothèques (pour HTTP, parsing STIX, etc.). Il conviendra de maintenir ces dépendances à jour pour bénéficier des derniers patchs de sécurité. Le code lui-même doit être régulièrement revu pour corriger d’éventuelles vulnérabilités (par exemple, si le framework est open source, gérer les contributions et audits). Un fichier README ou documentation incitera à signaler les failles trouvées.

En respectant ces principes, TinyCTI assurera non seulement sa fonctionnalité de collecte d’IOCs, mais le fera de manière sûre et fiable, évitant de devenir lui-même un maillon faible. La sécurité doit être considérée à chaque étape du développement, même si le produit n’est pas directement exposé, car il traite des données potentiellement critiques (renseignements de menace) et utilise des secrets d’accès. Un cahier des charges technique se doit de le souligner pour que ces préoccupations ne soient pas négligées lors de l’implémentation.